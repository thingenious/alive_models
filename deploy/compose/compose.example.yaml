---

volumes:
  data_cache:
    name: "data_cache"

services:
  alive-models-init:
    image: &container-image "${CONTAINER_IMAGE:-local/alive-models}:${CONTAINER_TAG:-latest}"
    container_name: "${CONTAINER_NAME:-alive-models}-init"
    init: true
    environment: &alive-models-env
      ALIVE_MODELS: "${ALIVE_MODELS:-asr,fer,ser,nlp}"
      ALIVE_MODELS_HTTP_PORT: "${ALIVE_MODELS_HTTP_PORT:-8000}"
      ALIVE_MODELS_GRPC_PORT: "${ALIVE_MODELS_GRPC_PORT:-8001}"
      ALIVE_MODELS_METRICS_PORT: "${ALIVE_MODELS_METRICS_PORT:-8002}"
      ALIVE_MODELS_SAGEMAKER_PORT: "${ALIVE_MODELS_SAGEMAKER_PORT:-8080}"
      ALIVE_MODELS_ASR_MODEL_SIZE: "${ALIVE_MODELS_ASR_MODEL_SIZE:-distil-large-v3}"
      ALIVE_MODELS_SER_MODEL_REPO: "${ALIVE_MODELS_SER_MODEL_REPO:-hughlan1214/Speech_Emotion_Recognition_wav2vec2-large-xlsr-53_240304_SER_fine-tuned2.0}"
      ALIVE_MODELS_NLP_MODEL_REPO: "${ALIVE_MODELS_NLP_MODEL_REPO:-SamLowe/roberta-base-go_emotions-onnx}"
      ALIVE_MODELS_NLP_MODEL_FILE: "${ALIVE_MODELS_NLP_MODEL_FILE:-onnx/model_quantized.onnx}"
      ALIVE_MODELS_ASR_MODEL_NAME: "${ALIVE_MODELS_ASR_MODEL_NAME:-asr}"
      ALIVE_MODELS_ASR_MODEL_VERSION: "${ALIVE_MODELS_ASR_MODEL_VERSION:-1}"
      ALIVE_MODELS_FER_MODEL_NAME: "${ALIVE_MODELS_FER_MODEL_NAME:-fer}"
      ALIVE_MODELS_FER_MODEL_VERSION: "${ALIVE_MODELS_FER_MODEL_VERSION:-1}"
      ALIVE_MODELS_FER_MODEL_DETECTOR_BACKEND: "${ALIVE_MODELS_FER_MODEL_DETECTOR_BACKEND:-yolov8}"
      ALIVE_MODELS_FER_MODEL_FACE_MIN_CONFIDENCE: "${ALIVE_MODELS_FER_MODEL_FACE_MIN_CONFIDENCE:-0.7}"
      ALIVE_MODELS_SER_MODEL_NAME: "${ALIVE_MODELS_SER_MODEL_NAME:-ser}"
      ALIVE_MODELS_SER_MODEL_VERSION: "${ALIVE_MODELS_SER_MODEL_VERSION:-1}"
      ALIVE_MODELS_NLP_MODEL_NAME: "${ALIVE_MODELS_NLP_MODEL_NAME:-nlp}"
      ALIVE_MODELS_NLP_MODEL_VERSION: "${ALIVE_MODELS_NLP_MODEL_VERSION:-1}"
      ALIVE_MODELS_ALLOW_HTTP: "${ALIVE_MODELS_ALLOW_HTTP:-true}"
      ALIVE_MODELS_ALLOW_GRPC: "${ALIVE_MODELS_ALLOW_GRPC:-true}"
      ALIVE_MODELS_ALLOW_METRICS: "${ALIVE_MODELS_ALLOW_METRICS:-true}"
      ALIVE_MODELS_ALLOW_SAGEMAKER: "${ALIVE_MODELS_ALLOW_SAGEMAKER:-false}"
      ALIVE_MODELS_GRPC_USE_SSL: "${ALIVE_MODELS_GRPC_USE_SSL:-false}"
      ALIVE_MODELS_GRPC_USE_SSL_MUTUAL: "${ALIVE_MODELS_GRPC_USE_SSL_MUTUAL:-false}"
      ALIVE_MODELS_GRPC_ROOT_CERT: "${ALIVE_MODELS_GRPC_ROOT_CERT:-}"
      ALIVE_MODELS_GRPC_SERVER_CERT: "${ALIVE_MODELS_GRPC_SERVER_CERT:-}"
      ALIVE_MODELS_GRPC_SERVER_KEY: "${ALIVE_MODELS_GRPC_SERVER_KEY:-}"
      NVIDIA_VISIBLE_DEVICES: nvidia.com/gpu=all
    volumes:
      - "data_cache:/opt/ml/data"
    command: ["/opt/ml/init.sh"]
    # yamllint disable rule:comments-indentation
    deploy: &alive-models-deploy
      resources:
        limits:
          cpus: "4"
          memory: "8G"
        reservations:
          cpus: "2"
          memory: "4G"
          ## for gpu:
          ## with docker-compose use:
          # devices:
          #   - driver: nvidia
          #     count: 1
          #     capabilities: [gpu]
    ## with podman-compose use:
    # devices:
    #   - nvidia.com/gpu=all
    ##
    # yamllint enable rule:comments-indentation
  alive-models:
    image: *container-image
    container_name: "${CONTAINER_NAME:-alive-models}"
    volumes:
      - "data_cache:/opt/ml/data"
    environment: *alive-models-env
    ports:
      - "${ALIVE_MODELS_HTTP_PORT:-8000}:${ALIVE_MODELS_HTTP_PORT:-8000}"
      - "${ALIVE_MODELS_GRPC_PORT:-8001}:${ALIVE_MODELS_GRPC_PORT:-8001}"
      - "${ALIVE_MODELS_METRICS_PORT:-8002}:${ALIVE_MODELS_METRICS_PORT:-8002}"
      - "${ALIVE_MODELS_SAGEMAKER_PORT:-8080}:${ALIVE_MODELS_SAGEMAKER_PORT:-8080}"
    depends_on:
      alive-models-init:
        condition: service_completed_successfully
    shm_size: 8G
    deploy: *alive-models-deploy
    ## with podman-compose use:
    devices:
      - nvidia.com/gpu=all
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${ALIVE_MODELS_HTTP_PORT:-8000}/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    logging:
      options:
        max-size: "50m"
        max-file: "10"
      driver: "json-file"
